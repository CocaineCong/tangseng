# ç´¢å¼•å¹³å°

> index_platform å¤„ç† & å­˜å‚¨å€’æ’ç´¢å¼•ï¼Œæ­£æ’ç´¢å¼•ç»“æ„.

## é¡¹ç›®ç»“æ„

```shell
index_platform
â”œâ”€â”€ analyzer            // è§£æå™¨ï¼Œåˆ†è¯ä½œç”¨ï¼Œä¸æœç´¢å¹³å°çš„è§£æä¸ä¸€æ ·
â”œâ”€â”€ cmd                 // é¡¹ç›®å¯åŠ¨å…¥å£
â”‚   â”œâ”€â”€ job             // è„šæœ¬æ³¨å†Œ
â”‚   â””â”€â”€ kfk_register    // kafkaæ¶ˆè´¹æ³¨å†Œ
â”œâ”€â”€ consts              // å­˜æ”¾è¯¥æ¨¡å—ä¸‹çš„å¸¸é‡
â”œâ”€â”€ crawl               // çˆ¬è™«(å¤§é¥¼ğŸ«“)
â”œâ”€â”€ input_data          // è¾“å…¥çš„æ•°æ®
â”œâ”€â”€ repository          // å­˜å‚¨ä»‹è´¨
â”‚   â”œâ”€â”€ db              // OLTP:mysql
â”‚   â”‚   â””â”€â”€ dao
â”‚   â”œâ”€â”€ starrock        // OLAP:starrocks 
â”‚   â”‚   â”œâ”€â”€ bi_dao
â”‚   â”‚   â””â”€â”€ initdb.d
â”‚   â””â”€â”€ storage         // KV DB: boltdb
â”œâ”€â”€ service             // æœåŠ¡å±‚
â””â”€â”€ trie                // å­˜å‚¨trieç›¸å…³ï¼Œæš‚æ—¶æ— ç”¨.
```

## æœåŠ¡å±‚è¯¦è§£

> ä¸»è¦ä¸šåŠ¡é€»è¾‘åœ¨è¿™ä¸ªæ–‡ä»¶ `app/index_platform/service/index_platform.go`

### 1. å€’æ’ç´¢å¼•

å®šä¹‰å€’æ’ç´¢å¼•ç»“æ„

```go
invertedIndex := cmap.New[*roaring.Bitmap]() // å€’æ’ç´¢å¼•
```

è€ƒè™‘åˆ°æ”¯æŒå¹¶å‘ï¼Œæ‰€ä»¥è¿™é‡Œç”¨çš„æ˜¯ç¬¬ä¸‰æ–¹çš„mapç»“æ„ï¼Œ`github.com/orcaman/concurrent-map/v2`,ç›¸æ¯”è¾ƒäºå®˜æ–¹syncåŒ…ä¸‹çš„mapç»“æ„æ›´é€‚åˆï¼Œé€‚åˆ**å¹¶å‘è¯»å†™ã€‚**

å­˜å‚¨ç´¢å¼•idä½¿ç”¨çš„æ•°æ®ç»“æ„æ˜¯`roaring bitmap`, `github.com/RoaringBitmap/roaring` æ˜¯ä¸€ç§bitmapçš„æ‰©å±•ï¼Œæ›´èƒ½å‹ç¼©ç©ºé—´ã€‚

> åé¢è¡¥å……ä¸€ä¸‹roaring bitmapçš„æ•°æ®ç»“æ„


### 2. mapreduceæ„å»ºç´¢å¼•

ç¬¬ä¸€ç‰ˆçš„mapreduceæ˜¯ä½¿ç”¨çš„æ˜¯grpcè¿›è¡Œå¤„ç†workerèŠ‚ç‚¹ã€‚ç¬¬äºŒç‰ˆé‡‡ç”¨chanå’Œgoroutineæ¥å¤„ç†workerï¼Œä»¥å‡å°‘rpcçš„è°ƒç”¨ã€‚

```go
_, _ = mapreduce.MapReduce(func(source chan<- []byte) {
    // è¾“å…¥çš„æ–‡ä»¶
    for _, path := range req.FilePath {
        content, _ := os.ReadFile(path)
        source <- content
    }
}, func(item []byte, writer mapreduce.Writer[[]*types.KeyValue], cancel func(error)) {
    // æ§åˆ¶å¹¶å‘
    var wg sync.WaitGroup
    ch := make(chan struct{}, 3)

    keyValueList := make([]*types.KeyValue, 0, 1e3)
    lines := strings.Split(string(item), "\r\n")
    for _, line := range lines[1:] {
        ch <- struct{}{}
        wg.Add(1)
        // è¾“å…¥çš„lineç»“æ„
        docStruct, _ := input_data.Doc2Struct(line) // line è½¬ docs struct
        if docStruct.DocId == 0 {
            continue
        }

        // åˆ†è¯
        tokens, _ := analyzer.GseCutForBuildIndex(docStruct.DocId, docStruct.Body)
        for _, v := range tokens {
            if v.Token == "" || v.Token == " " {
                continue
            }
            keyValueList = append(keyValueList, &types.KeyValue{
                    Key: v.Token, 
                    Value: cast.ToString(v.DocId)
                })
            // å‰ç¼€æ ‘çš„æ’å…¥
            dictTrie.Insert(v.Token)
        }

        // å»ºç«‹æ­£æ’ç´¢å¼•
        go func(docStruct *types.Document) {
            err = input_data.DocData2Kfk(docStruct)
            if err != nil {
                logs.LogrusObj.Error(err)
            }
            defer wg.Done()
            <-ch
        }(docStruct)
    }
    wg.Wait()
    // æ’åºshuffleæ“ä½œ
    sort.Sort(types.ByKey(keyValueList))
    writer.Write(keyValueList)
}, func(pipe <-chan []*types.KeyValue, writer mapreduce.Writer[string], cancel func(error)) {
    for values := range pipe {
        for _, v := range values { // æ„å»ºå€’æ’ç´¢å¼•
            if value, ok := invertedIndex.Get(v.Key); ok {
                value.AddInt(cast.ToInt(v.Value))
                invertedIndex.Set(v.Key, value)
            } else {
                docIds := roaring.NewBitmap()
                docIds.AddInt(cast.ToInt(v.Value))
                invertedIndex.Set(v.Key, docIds)
            }
        }
    }
})
```

mapæ“ä½œä¸­ï¼Œæˆ‘ä»¬æ‹†åˆ†å‡ºæ‰€æœ‰çš„è¯ä»¥åŠå¯¹åº”çš„idï¼Œå¦‚ä»¥ä¸‹æ•°æ®ç»“æ„

eg: 

1:é‚£é‡Œæ¹–é¢æ€»æ˜¯æ¾„æ¸…
2:é‚£é‡Œç©ºæ°”å……æ»¡å®é™

```
é‚£é‡Œ:1
æ¹–é¢:1
æ€»æ˜¯:1
æ¾„æ¸…:1
é‚£é‡Œ:2
ç©ºæ°”:2
å……æ»¡:2
å®é™:2
```

reduceæ“ä½œä¸­,æˆ‘ä»¬èšåˆæ‰€æœ‰ç›¸åŒvalueçš„ç»“æ„,æ„é€ å‡ºå€’æ’ç´¢å¼•çš„æœºæ„

```
é‚£é‡Œ:1,2
æ¹–é¢:1
æ€»æ˜¯:1
æ¾„æ¸…:1
ç©ºæ°”:2
å……æ»¡:2
å®é™:2
```

å¦å¤–åœ¨æ„é€ çš„è¿‡ç¨‹ä¸­ï¼Œä¹Ÿå°†æ¶ˆæ¯ä¹Ÿç”Ÿäº§ç»™kafkaè¿›è¡Œæ¶ˆè´¹ï¼Œä¸‹æ¸¸è¿›è¡Œkafkaçš„ç›‘å¬ï¼Œå¹¶ç”Ÿæˆmysqlçš„æ­£æ’ç´¢å¼•ï¼Œä¸€çº§milvusçš„å‘é‡ç´¢å¼•ã€‚

```go
go func(docStruct *types.Document) {
    err = input_data.DocData2Kfk(docStruct)
    if err != nil {
        logs.LogrusObj.Error(err)
    }
    defer wg.Done()
    <-ch
}(docStruct)
```

### 3. å­˜å‚¨ç»“æ„

åœ¨å­˜å‚¨ç´¢å¼•çš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä¹Ÿé‡‡ç”¨äº†å¼‚æ­¥å¤„ç†ï¼Œä½†æ³¨æ„è¿™é‡Œæˆ‘ä»¬éœ€è¦å…‹éš†ä¸€ä¸ªcontextï¼Œå¦åˆ™å®¹æ˜“é€ æˆ`context cancel`,å› ä¸ºè¿™ä¸ªctxæ˜¯ä¸»è¿›ç¨‹çš„ï¼Œä¸»è¿›ç¨‹ç»“æŸäº†è‡ªç„¶å°±canceläº†ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦cloneä¸€ä¸ªæ–°çš„ï¼Œæ¥è¿›è¡Œä¼ é€’ã€‚å…·ä½“å…‹éš†çš„ä»£ç åœ¨ `pkg/clone/context.go` è¿™éƒ¨åˆ†ä¼šå¦å¤–å¼€ä¸€ç¯‡è¯¦ç»†æ¥è®².

```go
go func() {
    newCtx := clone.NewContextWithoutDeadline()
    newCtx.Clone(ctx)
    err = storeInvertedIndexByHash(newCtx, invertedIndex)
    if err != nil {
        logs.LogrusObj.Error("storeInvertedIndexByHash error ", err)
    }
}()
```

boltdbå­˜å‚¨

```go
func storeInvertedIndexByHash(ctx context.Context, invertedIndex cmap.ConcurrentMap[string, *roaring.Bitmap]) (err error) {
	dir, _ := os.Getwd()
	outName := fmt.Sprintf("%s/%s.%s", dir, timeutils.GetNowTime(), cconsts.InvertedBucket)
	invertedDB := storage.NewInvertedDB(outName)
	// å¯¹æ‰€æœ‰çš„keyè¿›è¡Œå­˜å‚¨
	for k, val := range invertedIndex.Items() {
		outByte, errx := val.MarshalBinary()
		if errx != nil {
			logs.LogrusObj.Error("storeInvertedIndexByHash-MarshalBinary", errx)
			continue
		}
		err = invertedDB.StoragePostings(k, outByte)
		if err != nil {
			logs.LogrusObj.Error("storeInvertedIndexByHash-StoragePostings", err)
			continue
		}
	}
	invertedDB.Close()
	err = redis.PushInvertedPath(ctx, redis.InvertedIndexDbPathDayKey, []string{outName})
	if err != nil {
		logs.LogrusObj.Error(err)
		return
	}
	return
}
```

### 4. å‰ç¼€æ ‘

> å‰ç¼€æ ‘ç›¸å…³çš„åœ¨ `pkg/trie/trie.go` æ–‡ä»¶ä¸­

å®šä¹‰å‰ç¼€æ ‘ç»“æ„

```go
dictTrie := trie.NewTrie()  // å‰ç¼€æ ‘
```

å®šä¹‰å‰ç¼€æ ‘çš„nodeç»“æ„, ç”±äº `cmap.ConcurrentMap[string, *TrieNode]` æ²¡æ³•ååºåˆ—åŒ–ï¼Œå¯ä»¥åºåˆ—åŒ–jsonæˆstringæ ¼å¼è¿›è¡Œå­˜å‚¨ï¼Œä½†æ— æ³•ä»stringååºåˆ—åŒ–jsonè¿›è¡Œè¯»å–ï¼Œäºæ˜¯å¼•å…¥`ChildrenRecall`æ¥å¤„ç†å¬å›è¯·æ±‚ã€‚è¿™ä¸ªå¬å›ç« èŠ‚å†è®²è§£ã€‚

```go
type TrieNode struct {
	IsEnd          bool                                  `json:"is_end"`   // æ ‡è®°è¯¥èŠ‚ç‚¹æ˜¯å¦ä¸ºä¸€ä¸ªå•è¯çš„æœ«å°¾
	Children       cmap.ConcurrentMap[string, *TrieNode] `json:"children"` // å­˜å‚¨å­èŠ‚ç‚¹çš„æŒ‡é’ˆ
	ChildrenRecall map[string]*TrieNode                  `json:"children_recall"`
}
```

æ’å…¥å‰ç¼€æ ‘

```go
func (trie *Trie) Insert(word string) {
	words := []rune(word)
	node := trie.Root
	for i := 0; i < len(words); i++ {
		c := string(words[i])
		if _, ok := node.Children.Get(c); !ok {
			node.Children.Set(c, NewTrieNode())
		}
		node, _ = node.Children.Get(c)
	}
	node.IsEnd = true
}
```

æŸ¥è¯¢å‰ç¼€æ ‘

```go
func (trie *Trie) FindAllByPrefix(prefix string) []string {
	prefixs := []rune(prefix)
	node := trie.Root
	for i := 0; i < len(prefixs); i++ {
		c := string(prefixs[i])
		if _, ok := node.Children.Get(c); !ok {
			return nil
		}
		node, _ = node.Children.Get(c)
	}
	words := make([]string, 0)
	trie.dfs(node, prefix, &words)
	return words
}
```